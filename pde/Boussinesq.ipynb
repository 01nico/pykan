{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_WIDTH = 30\n",
    "DEFAULT_DEPTH = 7\n",
    "\n",
    "class PINN_f(nn.Module):\n",
    "    def __init__(self, width=DEFAULT_WIDTH, depth=DEFAULT_DEPTH):\n",
    "        super(PINN_f, self).__init__()\n",
    "        self.width = width\n",
    "        if depth < 2:\n",
    "            raise ValueError(f\"depth must be at least 2, got {depth}\")\n",
    "        self.depth = depth\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "        # layer definitions\n",
    "        self.FC_dict = nn.ModuleDict()\n",
    "        self.FC_dict[f\"layer 1\"] = nn.Linear(2, self.width)\n",
    "        for i in range(2, depth):\n",
    "            self.FC_dict[f\"layer {i}\"] = nn.Linear(self.width, self.width)\n",
    "        self.FC_dict[f\"layer {depth}\"] = nn.Linear(self.width, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for key, layer in self.FC_dict.items():\n",
    "            x = layer(x)\n",
    "            if key != f\"layer {self.depth}\":\n",
    "                x = self.act(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINN_f(\n",
      "  (act): Tanh()\n",
      "  (FC_dict): ModuleDict(\n",
      "    (layer 1): Linear(in_features=2, out_features=30, bias=True)\n",
      "    (layer 2): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (layer 3): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (layer 4): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (layer 5): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (layer 6): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (layer 7): Linear(in_features=30, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_phi = PINN_f().to(device)\n",
    "model_psi = PINN_f().to(device)\n",
    "model_w = PINN_f().to(device)\n",
    "model_u1 = PINN_f().to(device)\n",
    "model_u2 = PINN_f().to(device)\n",
    "\n",
    "print(model_u1)\n",
    "d_INIT = 3\n",
    "l = torch.tensor([d_INIT,], dtype=torch.float64, device=device, requires_grad=True)\n",
    "# define an optimizer\n",
    "params = list(model_psi.parameters()) + list(model_w.parameters())+ list(model_phi.parameters()) + list(model_u1.parameters())+list(model_u2.parameters())\n",
    "\n",
    "\n",
    "nn_optimizer = torch.optim.Adam(params, lr=0.001, weight_decay=0)\n",
    "#nn_scheduler = torch.optim.lr_scheduler.StepLR(nn_optimizer, step_size=1000, gamma=0.5)\n",
    "l_optimizer = torch.optim.Adam([l], lr=0.01, weight_decay=0) #l learning rate can be even better\n",
    "#l_scheduler = torch.optim.lr_scheduler.StepLR(l_optimizer, step_size=1000, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6j/b6y80djd4nb5hl73rv3sv8y80000gn/T/ipykernel_73645/1673218994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m#compute the equation residue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mf_1_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msinh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu1_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_1_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msinh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu2_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_2_s\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mphi_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0mf_2_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu1_1_s\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msinh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu1_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi_1_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msinh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu2_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi_2_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu2_1_s\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpsi_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mf_3_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu2_2_s\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpsi_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msinh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu1_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpsi_1_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msinh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu2_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpsi_2_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu1_2_s\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z1' is not defined"
     ]
    }
   ],
   "source": [
    "# adam without smoothness loss, fixed l\n",
    "batchsize = 5000 #interior\n",
    "batchsize1 = 500 #boundary, smoothness? (close to the origin)\n",
    "for ep in range(100000):\n",
    "    nn_optimizer.zero_grad()\n",
    "\n",
    "    #l_optimizer.zero_grad()\n",
    "\n",
    "    ### equation loss\n",
    "    # sample points uniformly in the transformed coordinates [-30,30]x[0,30]\n",
    "    c = 30\n",
    "    x1 = c*torch.rand(batchsize, 1, device=device)# (batch, 1)\n",
    "    x1.requires_grad=True\n",
    "    x2 = c*torch.rand(batchsize, 1, device=device) # (batch, 1)\n",
    "    x2.requires_grad=True\n",
    "    input1 = torch.cat([x1,x2], dim=-1) # (batch, 2)\n",
    "    input2 = torch.cat([-x1,x2], dim=-1) # (batch, 2)\n",
    "    phi = model_phi(input1)-model_phi(input2) # odd  parity\n",
    "    psi = model_psi(input1)+model_psi(input2) #even\n",
    "    w = model_w(input1)-model_w(input2) #odd\n",
    "    u1 = model_u1(input1)-model_u1(input2) #odd\n",
    "    u2 = model_u2(input1)+model_u2(input2) #even\n",
    "    \n",
    "    \n",
    "    #compute the derivatives (only first orders)\n",
    "    w_1 = grad(w.sum(), x1, create_graph=True)[0]\n",
    "    w_2 = grad(w.sum(), x2, create_graph=True)[0]\n",
    "    phi_1 = grad(phi.sum(), x1, create_graph=True)[0]\n",
    "    phi_2 = grad(phi.sum(), x2, create_graph=True)[0]\n",
    "    psi_1 = grad(psi.sum(), x1, create_graph=True)[0]\n",
    "    psi_2 = grad(psi.sum(), x2, create_graph=True)[0]\n",
    "    u1_1 = grad(u1.sum(), x1, create_graph=True)[0]\n",
    "    u1_2 = grad(u1.sum(), x2, create_graph=True)[0]\n",
    "    u2_1 = grad(u2.sum(), x1, create_graph=True)[0]\n",
    "    u2_2 = grad(u2.sum(), x2, create_graph=True)[0]\n",
    "    \n",
    "    #compute the equation residue\n",
    "    # note large/large might behave bad\n",
    "    N_e = 6\n",
    "    f_1 = w+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*w_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*w_2-phi\n",
    "    f_2 = (2+u1_1/torch.cosh(x1))*phi+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*phi_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*phi_2+u2_1/torch.cosh(x1)*psi\n",
    "    f_3 = (2+u2_2/torch.cosh(x2))*psi+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*psi_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*psi_2+u1_2/torch.cosh(x2)*phi\n",
    "    f_4 = u1_1/torch.cosh(x1)+u2_2/torch.cosh(x2)\n",
    "    f_5 = w-(u1_2/torch.cosh(x2)-u2_1/torch.cosh(x1))\n",
    "    f_6 = phi_2/torch.cosh(x2)-psi_1/torch.cosh(x1)\n",
    "    \n",
    "    loss_i_1=torch.norm(f_1)**2/batchsize\n",
    "    loss_i_2=torch.norm(f_2)**2/batchsize\n",
    "    loss_i_3=torch.norm(f_3)**2/batchsize\n",
    "    loss_i_4=torch.norm(f_4)**2/batchsize\n",
    "    loss_i_5=torch.norm(f_5)**2/batchsize\n",
    "    loss_i_6=torch.norm(f_6)**2/batchsize\n",
    "    \n",
    "    loss_i = (loss_i_1+loss_i_2+loss_i_3+loss_i_4+loss_i_5+loss_i_6)/N_e\n",
    "    \n",
    "    ###boundary loss\n",
    "    # sample points\n",
    "    y1 = c*torch.rand(batchsize1, 1, device=device)# (batch1, 1)\n",
    "    y1.requires_grad=True\n",
    "    y2 = c*torch.rand(batchsize1, 1, device=device) # (batch1, 1)\n",
    "    y2.requires_grad=True\n",
    "    y0 = torch.zeros(batchsize1,1, device=device,requires_grad=True)\n",
    "    yd = c*torch.ones(batchsize1,1, device=device)\n",
    "    yd.requires_grad=True\n",
    "    \n",
    "    #boundary 1\n",
    "    input1_b1 = torch.cat([y1,y0], dim=-1) # (batch1, 2)\n",
    "    input2_b1 = torch.cat([-y1,y0], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u2_b1 = model_u2(input1_b1)+model_u2(input2_b1) #even\n",
    "    b_1 = u2_b1\n",
    "    loss_b_1 = torch.norm(b_1)**2/batchsize1\n",
    "    \n",
    "    #boundary 2\n",
    "    o1 = torch.zeros(1,1, device=device,requires_grad=True)\n",
    "    o2 = torch.zeros(1,1, device=device,requires_grad=True)\n",
    "    input_b2 = torch.cat([o1,o2], dim=-1)\n",
    "    \n",
    "    w_b2 = 2*model_w(input_b2)# odd derivative\n",
    "    w_1_b2 = grad(w_b2.sum(), o1, create_graph=True)[0]\n",
    "    b_2 = w_1_b2+1\n",
    "    loss_b_2 = torch.norm(b_2)**2\n",
    "    \n",
    "    #boundary 3,5,7\n",
    "    input1_b3 = torch.cat([yd,y2], dim=-1) # (batch1, 2)\n",
    "    input2_b3 = torch.cat([-yd,y2], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u1_b3 = model_u1(input1_b3)-model_u1(input2_b3) #odd\n",
    "    u2_b3 = model_u2(input1_b3)+model_u2(input2_b3) #even\n",
    "    phi_b3 = model_phi(input1_b3)-model_phi(input2_b3)# odd\n",
    "    psi_b3 = model_psi(input1_b3)+model_psi(input2_b3)# even\n",
    "    u1_1_b3 = grad(u1_b3.sum(), yd, create_graph=True)[0]\n",
    "    u1_2_b3 = grad(u1_b3.sum(), y2, create_graph=True)[0]\n",
    "    u2_1_b3 = grad(u2_b3.sum(), yd, create_graph=True)[0]\n",
    "    u2_2_b3 = grad(u2_b3.sum(), y2, create_graph=True)[0]\n",
    "    b_31=u1_1_b3/torch.cosh(yd)\n",
    "    b_33=u1_2_b3/torch.cosh(y2)\n",
    "    b_34=u2_1_b3/torch.cosh(yd)\n",
    "    b_32=u2_2_b3/torch.cosh(y2)\n",
    "    b_5=phi_b3\n",
    "    b_7=psi_b3\n",
    "    loss_b_3 = (torch.norm(b_31)**2+torch.norm(b_32)**2+torch.norm(b_33)**2+torch.norm(b_34)**2+torch.norm(b_5)**2+torch.norm(b_7)**2)/batchsize1\n",
    "    \n",
    "    #boundary 4,6,8\n",
    "    input1_b4 = torch.cat([torch.sinh(y1),torch.sinh(yd)], dim=-1) # (batch1, 2)\n",
    "    input2_b4 = torch.cat([-torch.sinh(y1),torch.sinh(yd)], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u1_b4 = model_u1(input1_b4)-model_u1(input2_b4) #odd\n",
    "    u2_b4 = model_u2(input1_b4)+model_u2(input2_b4) #even\n",
    "    phi_b4 = model_phi(input1_b4)-model_phi(input2_b4)# odd\n",
    "    psi_b4 = model_psi(input1_b4)+model_psi(input2_b4)# even\n",
    "    u1_1_b4 = grad(u1_b4.sum(), y1, create_graph=True)[0]\n",
    "    u1_2_b4 = grad(u1_b4.sum(), yd, create_graph=True)[0]\n",
    "    u2_1_b4 = grad(u2_b4.sum(), y1, create_graph=True)[0]\n",
    "    u2_2_b4 = grad(u2_b4.sum(), yd, create_graph=True)[0]\n",
    "    b_41=u1_1_b4/torch.cosh(y1)\n",
    "    b_43=u1_2_b4/torch.cosh(yd)\n",
    "    b_44=u2_1_b4/torch.cosh(y1)\n",
    "    b_42=u2_2_b4/torch.cosh(yd)\n",
    "    b_6=phi_b4\n",
    "    b_8=psi_b4\n",
    "    loss_b_4 = (torch.norm(b_41)**2+torch.norm(b_42)**2+torch.norm(b_43)**2+torch.norm(b_44)**2+torch.norm(b_6)**2+torch.norm(b_8)**2)/batchsize1\n",
    "    \n",
    "    #collect the residue\n",
    "    N_b=8\n",
    "    loss_b = (loss_b_1+loss_b_2+loss_b_3+loss_b_4)/N_b\n",
    "\n",
    "    #compute the equation residue\n",
    "    f_1_s = w+((1+l)*torch.sinh(z1)+u1_s)/torch.cosh(z1)*w_1_s+((1+l)*torch.sinh(z2)+u2_s)/torch.cosh(z2)*w_2_s-phi_s\n",
    "    f_2_s = (2+u1_1_s/torch.cosh(z1))*phi_s+((1+l)*torch.sinh(z1)+u1_s)/torch.cosh(z1)*phi_1_s+((1+l)*torch.sinh(z2)+u2_s)/torch.cosh(z2)*phi_2_s+u2_1_s/torch.cosh(z1)*psi_s\n",
    "    f_3_s = (2+u2_2_s/torch.cosh(z2))*psi_s+((1+l)*torch.sinh(z1)+u1_s)/torch.cosh(z1)*psi_1_s+((1+l)*torch.sinh(z2)+u2_s)/torch.cosh(z2)*psi_2_s+u1_2_s/torch.cosh(z2)*phi_s\n",
    "    f_4_s = u1_1_s/torch.cosh(z1)+u2_2_s/torch.cosh(z2)\n",
    "    f_5_s = w-(u1_2_s/torch.cosh(z2)-u2_1_s/torch.cosh(z1))\n",
    "    f_6_s = phi_2_s/torch.cosh(z2)-psi_1_s/torch.cosh(z1)\n",
    "    \n",
    "    #compute the residue derivatives\n",
    "    F_1_1=grad(f_1_s.sum(), z1, create_graph=True)[0]\n",
    "    F_1_2=grad(f_1_s.sum(), z2, create_graph=True)[0]\n",
    "    F_2_1=grad(f_2_s.sum(), z1, create_graph=True)[0]\n",
    "    F_2_2=grad(f_2_s.sum(), z2, create_graph=True)[0]\n",
    "    F_3_1=grad(f_3_s.sum(), z1, create_graph=True)[0]\n",
    "    F_3_2=grad(f_3_s.sum(), z2, create_graph=True)[0]\n",
    "    F_4_1=grad(f_4_s.sum(), z1, create_graph=True)[0]\n",
    "    F_4_2=grad(f_4_s.sum(), z2, create_graph=True)[0]\n",
    "    F_5_1=grad(f_5_s.sum(), z1, create_graph=True)[0]\n",
    "    F_5_2=grad(f_5_s.sum(), z2, create_graph=True)[0]\n",
    "    F_6_1=grad(f_6_s.sum(), z1, create_graph=True)[0]\n",
    "    F_6_2=grad(f_6_s.sum(), z2, create_graph=True)[0]\n",
    "    \n",
    "\n",
    "    loss_s_1=(torch.norm(F_1_1)**2+torch.norm(F_1_2)**2)/batchsize1\n",
    "    loss_s_2=(torch.norm(F_2_1)**2+torch.norm(F_2_2)**2)/batchsize1\n",
    "    loss_s_3=(torch.norm(F_3_1)**2+torch.norm(F_3_2)**2)/batchsize1\n",
    "    loss_s_4=(torch.norm(F_4_1)**2+torch.norm(F_4_2)**2)/batchsize1\n",
    "    loss_s_5=(torch.norm(F_5_1)**2+torch.norm(F_5_2)**2)/batchsize1\n",
    "    loss_s_6=(torch.norm(F_6_1)**2+torch.norm(F_6_2)**2)/batchsize1\n",
    "    \n",
    "    loss_s = (loss_s_1+loss_s_2+loss_s_3+loss_s_4+loss_s_5+loss_s_6)/N_e\n",
    "    \n",
    "    \n",
    "    #the total loss\n",
    "    gamma=0.1\n",
    "    loss =gamma*(loss_i+loss_s)+1*loss_b\n",
    "    # update the model\n",
    "    loss.backward()\n",
    "    nn_optimizer.step()\n",
    "    #nn_scheduler.step()\n",
    "\n",
    "    #l_optimizer.step()\n",
    "    #l_scheduler.step()\n",
    "\n",
    "    # plot\n",
    "    if ep % 10 == 0:\n",
    "        print(\"Epoch is {},  function loss is {}, boundary loss is {},  overall loss is {} \".format(ep, loss_i.item(),loss_b.item(), loss.item()))\n",
    "        #print(ep, 'loss' +{loss_i.item()}, loss_b.item(),loss1.item(),loss2.item(), loss.item())\n",
    "        if ep % 100 == 0:\n",
    "            print(l)\n",
    "            # uniformly sample from [r,z] \n",
    "            nr=1000\n",
    "            nz=500\n",
    "            gridr = np.linspace(-20, 20,num=nr)\n",
    "            gridz = np.linspace(0, 20, num=nz)\n",
    "            rr, zz = np.meshgrid(gridr,gridz)\n",
    "            input1 = np.stack([rr, zz], axis=2).reshape(nr*nz,2)\n",
    "            input1 = torch.tensor([input1],dtype=torch.float64).to(device)\n",
    "            input2 = np.stack([-rr, zz], axis=2).reshape(nr*nz,2)\n",
    "            input2 = torch.tensor([input2],dtype=torch.float64).to(device)\n",
    "            #print(input.shape)\n",
    "            phi = model_phi(input1).reshape(nz,nr)-model_phi(input2).reshape(nz,nr) # odd  parity\n",
    "            psi = model_psi(input1).reshape(nz,nr)+model_psi(input2).reshape(nz,nr) #even\n",
    "            w = model_w(input1).reshape(nz,nr)-model_w(input2).reshape(nz,nr) #odd\n",
    "            u1 = model_u1(input1).reshape(nz,nr)-model_u1(input2).reshape(nz,nr) #odd\n",
    "            u2 = model_u2(input1).reshape(nz,nr)+model_u2(input2).reshape(nz,nr) #even\n",
    "\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.set_title('u1')\n",
    "            ax.plot_surface(rr, zz, u1.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.set_title('u2')\n",
    "            ax.plot_surface(rr, zz, u2.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.set_title('w')\n",
    "            ax.plot_surface(rr, zz, w.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.set_title('phi')\n",
    "            ax.plot_surface(rr, zz, phi.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.set_title('psi')\n",
    "            ax.plot_surface(rr, zz, psi.detach().cpu().numpy())\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6j/b6y80djd4nb5hl73rv3sv8y80000gn/T/ipykernel_94736/4049212792.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatchsize1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;31m#boundary, smoothness? (close to the origin)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnn_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#l_optimizer.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn_optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "# adam input as function of y\n",
    "batchsize = 4000 #interior\n",
    "batchsize1 = 500 #boundary, smoothness? (close to the origin)\n",
    "for ep in range(1000):\n",
    "    nn_optimizer.zero_grad()\n",
    "\n",
    "    #l_optimizer.zero_grad()\n",
    "\n",
    "    ### equation loss\n",
    "    # sample points uniformly in the transformed coordinates [-30,30]x[0,30]\n",
    "    c = 30\n",
    "    d = 2\n",
    "    x11 = torch.sinh(c*torch.rand(batchsize, 1, device='cuda'))# (batch, 1)\n",
    "    x12 = torch.sinh(d*torch.rand(batchsize, 1, device='cuda'))\n",
    "    x1=torch.cat([x11,x12], dim=0)\n",
    "    x1.requires_grad=True\n",
    "    x21 = torch.sinh(c*torch.rand(batchsize, 1, device='cuda'))# (batch, 1)\n",
    "    x22 = torch.sinh(d*torch.rand(batchsize, 1, device='cuda'))\n",
    "    x2=torch.cat([x21,x22], dim=0) # (2batch, 1)\n",
    "    x2.requires_grad=True\n",
    "    input1 = torch.cat([x1,x2], dim=-1) # (2batch, 2)\n",
    "    input2 = torch.cat([-x1,x2], dim=-1) # (2batch, 2)\n",
    "    phi = model_phi(input1)-model_phi(input2) # odd  parity\n",
    "    psi = model_psi(input1)+model_psi(input2) #eve\n",
    "    w = model_w(input1)-model_w(input2) #odd\n",
    "    u1 = model_u1(input1)-model_u1(input2) #odd\n",
    "    u2 = model_u2(input1)+model_u2(input2) #even\n",
    "    \n",
    "    \n",
    "    #compute the derivatives (only first orders)\n",
    "    w_1 = grad(w.sum(), x1, create_graph=True)[0]\n",
    "    w_2 = grad(w.sum(), x2, create_graph=True)[0]\n",
    "    phi_1 = grad(phi.sum(), x1, create_graph=True)[0]\n",
    "    phi_2 = grad(phi.sum(), x2, create_graph=True)[0]\n",
    "    psi_1 = grad(psi.sum(), x1, create_graph=True)[0]\n",
    "    psi_2 = grad(psi.sum(), x2, create_graph=True)[0]\n",
    "    u1_1 = grad(u1.sum(), x1, create_graph=True)[0]\n",
    "    u1_2 = grad(u1.sum(), x2, create_graph=True)[0]\n",
    "    u2_1 = grad(u2.sum(), x1, create_graph=True)[0]\n",
    "    u2_2 = grad(u2.sum(), x2, create_graph=True)[0]\n",
    "    \n",
    "    #compute the equation residue\n",
    "    N_e = 6\n",
    "    f_1 = w+((1+l)*(x1)+u1)*w_1+((1+l)*(x2)+u2)*w_2-phi\n",
    "    f_2 = (2+u1_1)*phi+((1+l)*(x1)+u1)*phi_1+((1+l)*(x2)+u2)*phi_2+u2_1*psi\n",
    "    f_3 = (2+u2_2)*psi+((1+l)*(x1)+u1)*psi_1+((1+l)*(x2)+u2)*psi_2+u1_2*phi\n",
    "    f_4 = u1_1+u2_2\n",
    "    f_5 = w-(u1_2-u2_1)\n",
    "    f_6 = phi_2-psi_1\n",
    "    \n",
    "    loss_i_1=torch.norm(f_1)**2/batchsize\n",
    "    loss_i_2=torch.norm(f_2)**2/batchsize\n",
    "    loss_i_3=torch.norm(f_3)**2/batchsize\n",
    "    loss_i_4=torch.norm(f_4)**2/batchsize\n",
    "    loss_i_5=torch.norm(f_5)**2/batchsize\n",
    "    loss_i_6=torch.norm(f_6)**2/batchsize\n",
    "    \n",
    "    loss_i = (loss_i_1+loss_i_2+loss_i_3+loss_i_4+loss_i_5+loss_i_6)/N_e\n",
    "    \n",
    "    ###boundary loss\n",
    "    # sample points\n",
    "    y1 =torch.sinh(c*torch.rand(batchsize1, 1, device='cuda'))# (batch1, 1)\n",
    "    y1.requires_grad=True\n",
    "    y2 = torch.sinh(c*torch.rand(batchsize1, 1, device='cuda')) # (batch1, 1)\n",
    "    y2.requires_grad=True\n",
    "    y0 = torch.zeros(batchsize1,1, device='cuda',requires_grad=True)\n",
    "    yd = torch.sinh(c*torch.ones(batchsize1,1, device='cuda'))\n",
    "    yd.requires_grad=True\n",
    "    \n",
    "    #boundary 1\n",
    "    input1_b1 = torch.cat([(y1),(y0)], dim=-1) # (batch1, 2)\n",
    "    input2_b1 = torch.cat([-(y1),(y0)], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u2_b1 = model_u2(input1_b1)+model_u2(input2_b1) #even\n",
    "    b_1 = u2_b1\n",
    "    loss_b_1 = torch.norm(b_1)**2/batchsize1\n",
    "    \n",
    "    #boundary 2\n",
    "    o1 = torch.zeros(1,1, device='cuda',requires_grad=True)\n",
    "    o2 = torch.zeros(1,1, device='cuda',requires_grad=True)\n",
    "    input_b2 = torch.cat([o1,o2], dim=-1)\n",
    "    \n",
    "    w_b2 = 2*model_w(input_b2)# odd derivative\n",
    "    w_1_b2 = grad(w_b2.sum(), o1, create_graph=True)[0]\n",
    "    b_2 = w_1_b2+1\n",
    "    loss_b_2 = torch.norm(b_2)**2\n",
    "    \n",
    "    #boundary 3,5,7\n",
    "    input1_b3 = torch.cat([(yd),(y2)], dim=-1) # (batch1, 2)\n",
    "    input2_b3 = torch.cat([-(yd),y2], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u1_b3 = model_u1(input1_b3)-model_u1(input2_b3) #odd\n",
    "    u2_b3 = model_u2(input1_b3)+model_u2(input2_b3) #even\n",
    "    phi_b3 = model_phi(input1_b3)-model_phi(input2_b3)# odd\n",
    "    psi_b3 = model_psi(input1_b3)+model_psi(input2_b3)# even\n",
    "    u1_1_b3 = grad(u1_b3.sum(), yd, create_graph=True)[0]\n",
    "    u1_2_b3 = grad(u1_b3.sum(), y2, create_graph=True)[0]\n",
    "    u2_1_b3 = grad(u2_b3.sum(), yd, create_graph=True)[0]\n",
    "    u2_2_b3 = grad(u2_b3.sum(), y2, create_graph=True)[0]\n",
    "    b_31=u1_1_b3\n",
    "    b_33=u1_2_b3\n",
    "    b_34=u2_1_b3\n",
    "    b_32=u2_2_b3\n",
    "    b_5=phi_b3\n",
    "    b_7=psi_b3\n",
    "    loss_b_3 = (torch.norm(b_31)**2+torch.norm(b_32)**2+torch.norm(b_33)**2+torch.norm(b_34)**2+torch.norm(b_5)**2+torch.norm(b_7)**2)/batchsize1\n",
    "    \n",
    "    #boundary 4,6,8\n",
    "    input1_b4 = torch.cat([(y1),(yd)], dim=-1) # (batch1, 2)\n",
    "    input2_b4 = torch.cat([-(y1),(yd)], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u1_b4 = model_u1(input1_b4)-model_u1(input2_b4) #odd\n",
    "    u2_b4 = model_u2(input1_b4)+model_u2(input2_b4) #even\n",
    "    phi_b4 = model_phi(input1_b4)-model_phi(input2_b4)# odd\n",
    "    psi_b4 = model_psi(input1_b4)+model_psi(input2_b4)# even\n",
    "    u1_1_b4 = grad(u1_b4.sum(), y1, create_graph=True)[0]\n",
    "    u1_2_b4 = grad(u1_b4.sum(), yd, create_graph=True)[0]\n",
    "    u2_1_b4 = grad(u2_b4.sum(), y1, create_graph=True)[0]\n",
    "    u2_2_b4 = grad(u2_b4.sum(), yd, create_graph=True)[0]\n",
    "    b_41=u1_1_b4\n",
    "    b_43=u1_2_b4\n",
    "    b_44=u2_1_b4\n",
    "    b_42=u2_2_b4\n",
    "    b_6=phi_b4\n",
    "    b_8=psi_b4\n",
    "    loss_b_4 = (torch.norm(b_41)**2+torch.norm(b_42)**2+torch.norm(b_43)**2+torch.norm(b_44)**2+torch.norm(b_6)**2+torch.norm(b_8)**2)/batchsize1\n",
    "    \n",
    "    #collect the residue\n",
    "    N_b=8\n",
    "    loss_b = (loss_b_1+loss_b_2+loss_b_3+loss_b_4)/N_b\n",
    "    \n",
    "        \n",
    "    \n",
    "    #the total loss\n",
    "    gamma=0.1\n",
    "    loss =gamma*(loss_i)+1*loss_b\n",
    "\n",
    "    # update the model\n",
    "    loss.backward()\n",
    "    nn_optimizer.step()\n",
    "    #nn_scheduler.step()\n",
    "\n",
    "    #l_optimizer.step()\n",
    "    #l_scheduler.step()\n",
    "\n",
    "    # plot\n",
    "    if ep % 1000 == 0:\n",
    "        print(\"Epoch is {},  function loss is {}, boundary loss is {},  overall loss is {} \".format(ep, loss_i.item(),loss_b.item(), loss.item()))\n",
    "        #print(ep, 'loss' +{loss_i.item()}, loss_b.item(),loss1.item(),loss2.item(), loss.item())\n",
    "        print(l)\n",
    "        # uniformly sample from [r,z] \n",
    "        nr=1000\n",
    "        nz=500\n",
    "        gridr = np.linspace(-20, 20,num=nr)\n",
    "        gridz = np.linspace(0, 20, num=nz)\n",
    "        rr, zz = np.meshgrid(gridr,gridz)\n",
    "        input1 = np.stack([rr, zz], axis=2).reshape(nr*nz,2)\n",
    "        input1 = torch.tensor([input1],dtype=torch.float64).cuda()\n",
    "        input2 = np.stack([-rr, zz], axis=2).reshape(nr*nz,2)\n",
    "        input2 = torch.tensor([input2],dtype=torch.float64).cuda()\n",
    "        #print(input.shape)\n",
    "        phi = model_phi(input1).reshape(nz,nr)-model_phi(input2).reshape(nz,nr) # odd  parity\n",
    "        psi = model_psi(input1).reshape(nz,nr)+model_psi(input2).reshape(nz,nr) #even\n",
    "        w = model_w(input1).reshape(nz,nr)-model_w(input2).reshape(nz,nr) #odd\n",
    "        u1 = model_u1(input1).reshape(nz,nr)-model_u1(input2).reshape(nz,nr) #odd\n",
    "        u2 = model_u2(input1).reshape(nz,nr)+model_u2(input2).reshape(nz,nr) #even\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_title('u1')\n",
    "        ax.plot_surface(rr, zz, u1.detach().cpu().numpy())\n",
    "        plt.show()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_title('u2')\n",
    "        ax.plot_surface(rr, zz, u2.detach().cpu().numpy())\n",
    "        plt.show()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_title('w')\n",
    "        ax.plot_surface(rr, zz, w.detach().cpu().numpy())\n",
    "        plt.show()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_title('phi')\n",
    "        ax.plot_surface(rr, zz, phi.detach().cpu().numpy())\n",
    "        plt.show()\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_title('psi')\n",
    "        ax.plot_surface(rr, zz, psi.detach().cpu().numpy())\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam with smoothness loss, fixed l\n",
    "batchsize = 4000 #interior\n",
    "batchsize1 = 500 #boundary, smoothness? (close to the origin)\n",
    "for ep in range(100000):\n",
    "    nn_optimizer.zero_grad()\n",
    "\n",
    "    #l_optimizer.zero_grad()\n",
    "\n",
    "    ### equation loss\n",
    "    # sample points uniformly in the transformed coordinates [-30,30]x[0,30]\n",
    "    c = 30\n",
    "    d = 2\n",
    "    x11 = (c*torch.rand(batchsize, 1, device=device))# (batch, 1)\n",
    "    x12 = (d*torch.rand(batchsize, 1, device=device))\n",
    "    x1=torch.cat([x11,x12], dim=0)\n",
    "    x1.requires_grad=True\n",
    "    x21 = (c*torch.rand(batchsize, 1, device=device))# (batch, 1)\n",
    "    x22 = (d*torch.rand(batchsize, 1, device=device))\n",
    "    x2=torch.cat([x21,x22], dim=0) # (2batch, 1)\n",
    "    x2.requires_grad=True\n",
    "    input1 = torch.cat([x1,x2], dim=-1) # (batch, 2)\n",
    "    input2 = torch.cat([-x1,x2], dim=-1) # (batch, 2)\n",
    "    phi = model_phi(input1)-model_phi(input2) # odd  parity\n",
    "    psi = model_psi(input1)+model_psi(input2) #even\n",
    "    w = model_w(input1)-model_w(input2) #odd\n",
    "    u1 = model_u1(input1)-model_u1(input2) #odd\n",
    "    u2 = model_u2(input1)+model_u2(input2) #even\n",
    "    \n",
    "    \n",
    "    #compute the derivatives (only first orders)\n",
    "    w_1 = grad(w.sum(), x1, create_graph=True)[0]\n",
    "    w_2 = grad(w.sum(), x2, create_graph=True)[0]\n",
    "    phi_1 = grad(phi.sum(), x1, create_graph=True)[0]\n",
    "    phi_2 = grad(phi.sum(), x2, create_graph=True)[0]\n",
    "    psi_1 = grad(psi.sum(), x1, create_graph=True)[0]\n",
    "    psi_2 = grad(psi.sum(), x2, create_graph=True)[0]\n",
    "    u1_1 = grad(u1.sum(), x1, create_graph=True)[0]\n",
    "    u1_2 = grad(u1.sum(), x2, create_graph=True)[0]\n",
    "    u2_1 = grad(u2.sum(), x1, create_graph=True)[0]\n",
    "    u2_2 = grad(u2.sum(), x2, create_graph=True)[0]\n",
    "    \n",
    "    #compute the equation residue\n",
    "    N_e = 6\n",
    "    f_1 = w+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*w_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*w_2-phi\n",
    "    f_2 = (2+u1_1/torch.cosh(x1))*phi+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*phi_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*phi_2+u2_1/torch.cosh(x1)*psi\n",
    "    f_3 = (2+u2_2/torch.cosh(x2))*psi+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*psi_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*psi_2+u1_2/torch.cosh(x2)*phi\n",
    "    f_4 = u1_1/torch.cosh(x1)+u2_2/torch.cosh(x2)\n",
    "    f_5 = w-(u1_2/torch.cosh(x2)-u2_1/torch.cosh(x1))\n",
    "    f_6 = phi_2/torch.cosh(x2)-psi_1/torch.cosh(x1)\n",
    "    \n",
    "    loss_i_1=torch.norm(f_1)**2/batchsize\n",
    "    loss_i_2=torch.norm(f_2)**2/batchsize\n",
    "    loss_i_3=torch.norm(f_3)**2/batchsize\n",
    "    loss_i_4=torch.norm(f_4)**2/batchsize\n",
    "    loss_i_5=torch.norm(f_5)**2/batchsize\n",
    "    loss_i_6=torch.norm(f_6)**2/batchsize\n",
    "    \n",
    "    loss_i = (loss_i_1+loss_i_2+loss_i_3+loss_i_4+loss_i_5+loss_i_6)/N_e\n",
    "    \n",
    "    ###boundary loss\n",
    "    # sample points\n",
    "    y1 = 2*c*(torch.rand(batchsize1, 1, device=device)-1/2)# (batch1, 1)\n",
    "    y1.requires_grad=True\n",
    "    y2 = c*torch.rand(batchsize1, 1, device=device) # (batch1, 1)\n",
    "    y2.requires_grad=True\n",
    "    y0 = torch.zeros(batchsize1,1, device=device,requires_grad=True)\n",
    "    yd = c*torch.ones(batchsize1,1, device=device)\n",
    "    yd.requires_grad=True\n",
    "    \n",
    "    #boundary 1\n",
    "    input1_b1 = torch.cat([y1,y0], dim=-1) # (batch1, 2)\n",
    "    input2_b1 = torch.cat([-y1,y0], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u2_b1 = model_u2(input1_b1)+model_u2(input2_b1) #even\n",
    "    b_1 = u2_b1\n",
    "    loss_b_1 = torch.norm(b_1)**2/batchsize1\n",
    "    \n",
    "    #boundary 2\n",
    "    o1 = torch.zeros(1,1, device=device,requires_grad=True)\n",
    "    o2 = torch.zeros(1,1, device=device,requires_grad=True)\n",
    "    input_b2 = torch.cat([o1,o2], dim=-1)\n",
    "    w_b2 = 2*model_w(input_b2)# odd derivative\n",
    "    w_1_b2 = grad(w_b2.sum(), o1, create_graph=True)[0]\n",
    "    b_2 = w_1_b2+1\n",
    "    loss_b_2 = torch.norm(b_2)**2\n",
    "    #boundary 3,5,7\n",
    "    input1_b3 = torch.cat([yd,y2], dim=-1) # (batch1, 2)\n",
    "    input2_b3 = torch.cat([-yd,y2], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u1_b3 = model_u1(input1_b3)-model_u1(input2_b3) #odd\n",
    "    u2_b3 = model_u2(input1_b3)+model_u2(input2_b3) #even\n",
    "    phi_b3 = model_phi(input1_b3)-model_phi(input2_b3)# odd\n",
    "    psi_b3 = model_psi(input1_b3)+model_psi(input2_b3)# even\n",
    "    u1_1_b3 = grad(u1_b3.sum(), yd, create_graph=True)[0]\n",
    "    u1_2_b3 = grad(u1_b3.sum(), y2, create_graph=True)[0]\n",
    "    u2_1_b3 = grad(u2_b3.sum(), yd, create_graph=True)[0]\n",
    "    u2_2_b3 = grad(u2_b3.sum(), y2, create_graph=True)[0]\n",
    "    b_31=u1_1_b3/torch.cosh(yd)\n",
    "    b_33=u1_2_b3/torch.cosh(y2)\n",
    "    b_34=u2_1_b3/torch.cosh(yd)\n",
    "    b_32=u2_2_b3/torch.cosh(y2)\n",
    "    b_5=phi_b3\n",
    "    b_7=psi_b3\n",
    "    loss_b_3 = (torch.norm(b_31)**2+torch.norm(b_32)**2+torch.norm(b_33)**2+torch.norm(b_34)**2+torch.norm(b_5)**2+torch.norm(b_7)**2)/batchsize1\n",
    "    \n",
    "    #boundary 4,6,8\n",
    "    input1_b4 = torch.cat([y1,yd], dim=-1) # (batch1, 2)\n",
    "    input2_b4 = torch.cat([-y1,yd], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u1_b4 = model_u1(input1_b4)-model_u1(input2_b4) #odd\n",
    "    u2_b4 = model_u2(input1_b4)+model_u2(input2_b4) #even\n",
    "    phi_b4 = model_phi(input1_b4)-model_phi(input2_b4)# odd\n",
    "    psi_b4 = model_psi(input1_b4)+model_psi(input2_b4)# even\n",
    "    u1_1_b4 = grad(u1_b4.sum(), y1, create_graph=True)[0]\n",
    "    u1_2_b4 = grad(u1_b4.sum(), yd, create_graph=True)[0]\n",
    "    u2_1_b4 = grad(u2_b4.sum(), y1, create_graph=True)[0]\n",
    "    u2_2_b4 = grad(u2_b4.sum(), yd, create_graph=True)[0]\n",
    "    b_41=u1_1_b4/torch.cosh(y1)\n",
    "    b_43=u1_2_b4/torch.cosh(yd)\n",
    "    b_44=u2_1_b4/torch.cosh(y1)\n",
    "    b_42=u2_2_b4/torch.cosh(yd)\n",
    "    b_6=phi_b4\n",
    "    b_8=psi_b4\n",
    "    loss_b_4 = (torch.norm(b_41)**2+torch.norm(b_42)**2+torch.norm(b_43)**2+torch.norm(b_44)**2+torch.norm(b_6)**2+torch.norm(b_8)**2)/batchsize1\n",
    "    \n",
    "    #collect the residue\n",
    "    N_b=8\n",
    "    loss_b = (loss_b_1+loss_b_2+loss_b_3+loss_b_4)/N_b\n",
    "    \n",
    "    ### smoothness loss\n",
    "    # sample points uniformly in the transformed coordinates [-1,1]x[0,1]\n",
    "    x1 = 2*(torch.rand(batchsize1, 1, device=device)-1/2)# (batch, 1)\n",
    "    x1.requires_grad=True\n",
    "    x2 = torch.rand(batchsize1, 1, device=device) # (batch, 1)\n",
    "    x2.requires_grad=True\n",
    "    input1_s = torch.cat([x1,x2], dim=-1) # (batch, 2)\n",
    "    input2_s = torch.cat([-x1,x2], dim=-1) # (batch, 2)\n",
    "    phi = model_phi(input1_s)-model_phi(input2_s) # odd  parity\n",
    "    psi = model_psi(input1_s)+model_psi(input2_s) #even\n",
    "    w = model_w(input1_s)-model_w(input2_s) #odd\n",
    "    u1 = model_u1(input1_s)-model_u1(input2_s) #odd\n",
    "    u2 = model_u2(input1_s)+model_u2(input2_s) #even\n",
    "    \n",
    "\n",
    "    w_1 = grad(w.sum(), x1, create_graph=True)[0]\n",
    "    w_2 = grad(w.sum(), x2, create_graph=True)[0]\n",
    "    phi_1 = grad(phi.sum(), x1, create_graph=True)[0]\n",
    "    phi_2 = grad(phi.sum(), x2, create_graph=True)[0]\n",
    "    psi_1 = grad(psi.sum(), x1, create_graph=True)[0]\n",
    "    psi_2 = grad(psi.sum(), x2, create_graph=True)[0]\n",
    "    u1_1 = grad(u1.sum(), x1, create_graph=True)[0]\n",
    "    u1_2 = grad(u1.sum(), x2, create_graph=True)[0]\n",
    "    u2_1 = grad(u2.sum(), x1, create_graph=True)[0]\n",
    "    u2_2 = grad(u2.sum(), x2, create_graph=True)[0]\n",
    "    \n",
    "    #compute the equation residue\n",
    "    N_e = 6\n",
    "    f_1 = w+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*w_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*w_2-phi\n",
    "    f_2 = (2+u1_1/torch.cosh(x1))*phi+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*phi_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*phi_2+u2_1/torch.cosh(x1)*psi\n",
    "    f_3 = (2+u2_2/torch.cosh(x2))*psi+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*psi_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*psi_2+u1_2/torch.cosh(x2)*phi\n",
    "    f_4 = u1_1/torch.cosh(x1)+u2_2/torch.cosh(x2)\n",
    "    f_5 = w-(u1_2/torch.cosh(x2)-u2_1/torch.cosh(x1))\n",
    "    f_6 = phi_2/torch.cosh(x2)-psi_1/torch.cosh(x1)\n",
    "    \n",
    "\n",
    "    \n",
    "    #compute the residue derivatives\n",
    "    F_1_1=grad(f_1.sum(), x1, create_graph=True)[0]\n",
    "    F_1_2=grad(f_1.sum(), x2, create_graph=True)[0]\n",
    "    F_2_1=grad(f_2.sum(), x1, create_graph=True)[0]\n",
    "    F_2_2=grad(f_2.sum(), x2, create_graph=True)[0]\n",
    "    F_3_1=grad(f_3.sum(), x1, create_graph=True)[0]\n",
    "    F_3_2=grad(f_3.sum(), x2, create_graph=True)[0]\n",
    "    F_4_1=grad(f_4.sum(), x1, create_graph=True)[0]\n",
    "    F_4_2=grad(f_4.sum(), x2, create_graph=True)[0]\n",
    "    F_5_1=grad(f_5.sum(), x1, create_graph=True)[0]\n",
    "    F_5_2=grad(f_5.sum(), x2, create_graph=True)[0]\n",
    "    F_6_1=grad(f_6.sum(), x1, create_graph=True)[0]\n",
    "    F_6_2=grad(f_6.sum(), x2, create_graph=True)[0]\n",
    "    \n",
    "\n",
    "    loss_s_1=(torch.norm(F_1_1)**2+torch.norm(F_1_2)**2)/batchsize1\n",
    "    loss_s_2=(torch.norm(F_2_1)**2+torch.norm(F_2_2)**2)/batchsize1\n",
    "    loss_s_3=(torch.norm(F_3_1)**2+torch.norm(F_3_2)**2)/batchsize1\n",
    "    loss_s_4=(torch.norm(F_4_1)**2+torch.norm(F_4_2)**2)/batchsize1\n",
    "    loss_s_5=(torch.norm(F_5_1)**2+torch.norm(F_5_2)**2)/batchsize1\n",
    "    loss_s_6=(torch.norm(F_6_1)**2+torch.norm(F_6_2)**2)/batchsize1\n",
    "    \n",
    "    loss_s = (loss_s_1+loss_s_2+loss_s_3+loss_s_4+loss_s_5+loss_s_6)/N_e\n",
    "    \n",
    "    \n",
    "    #the total loss\n",
    "    gamma=0.1\n",
    "    loss =gamma*(loss_i+loss_s)+1*loss_b\n",
    "\n",
    "    # update the model\n",
    "    loss.backward()\n",
    "    nn_optimizer.step()\n",
    "    #nn_scheduler.step()\n",
    "\n",
    "    #l_optimizer.step()\n",
    "    #l_scheduler.step()\n",
    "\n",
    "    # plot\n",
    "    if ep % 10 == 0:\n",
    "        print(\"Epoch is {},  function loss is {}, boundary loss is {}, smoothness loss is {}, overall loss is {} \".format(ep, loss_i.item(),loss_b.item(),loss_s.item(), loss.item()))\n",
    "        #print(ep, 'loss' +{loss_i.item()}, loss_b.item(),loss1.item(),loss2.item(), loss.item())\n",
    "        if ep % 100 == 0:\n",
    "            print(l)\n",
    "            # uniformly sample from [r,z] \n",
    "            nr=1001\n",
    "            nz=501\n",
    "            gridr = np.linspace(-20, 20,num=nr)\n",
    "            gridz = np.linspace(0, 20, num=nz)\n",
    "            rr, zz = np.meshgrid(gridr,gridz)\n",
    "            x1=torch.tensor([np.arcsinh(rr).reshape(nr*nz,1)],dtype=torch.float64,requires_grad=True).to(device)\n",
    "            x2=torch.tensor([np.arcsinh(zz).reshape(nr*nz,1)],dtype=torch.float64).to(device)\n",
    "            input1 = torch.cat([x1,x2], dim=-1)\n",
    "            input2 = torch.cat([-x1,x2], dim=-1)\n",
    "            #print(input.shape)\n",
    "            phi = model_phi(input1).reshape(nz,nr)-model_phi(input2).reshape(nz,nr) # odd  parity\n",
    "            psi = model_psi(input1).reshape(nz,nr)+model_psi(input2).reshape(nz,nr) #even\n",
    "            w = model_w(input1)-model_w(input2) #odd\n",
    "            w_1 = grad(w.sum(), x1, create_graph=True)[0]\n",
    "            w = w.reshape(nz,nr) #odd\n",
    "            w_1 = w_1.reshape(nz,nr)\n",
    "            u1 = model_u1(input1).reshape(nz,nr)-model_u1(input2).reshape(nz,nr) #odd\n",
    "            u2 = model_u2(input1).reshape(nz,nr)+model_u2(input2).reshape(nz,nr) #even\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.set_title('u1')\n",
    "            ax.plot_surface(rr, zz, u1.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.set_title('u2')\n",
    "            ax.plot_surface(rr, zz, u2.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.set_title('w')\n",
    "            ax.plot_surface(rr, zz, w.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.set_title('phi')\n",
    "            ax.plot_surface(rr, zz, phi.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.set_title('psi')\n",
    "            ax.plot_surface(rr, zz, psi.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam with smoothness loss, optimize l\n",
    "batchsize = 1000 #interior\n",
    "batchsize1 = 500 #boundary, smoothness? (close to the origin)\n",
    "for ep in range(100000):\n",
    "    nn_optimizer.zero_grad()\n",
    "\n",
    "    l_optimizer.zero_grad()\n",
    "\n",
    "    ### equation loss\n",
    "    # sample points uniformly in the transformed coordinates [-30,30]x[-30,30]\n",
    "    c = 30\n",
    "    x1 = 2*c*(torch.rand(batchsize, 1, device=device)-1/2)# (batch, 1)\n",
    "    x1.requires_grad=True\n",
    "    x2 = c*torch.rand(batchsize, 1, device=device) # (batch, 1)\n",
    "    x2.requires_grad=True\n",
    "    input1 = torch.cat([x1,x2], dim=-1) # (batch, 2)\n",
    "    input2 = torch.cat([-x1,x2], dim=-1) # (batch, 2)\n",
    "    phi = model_phi(input1)-model_phi(input2) # odd  parity\n",
    "    psi = model_psi(input1)+model_psi(input2) #even\n",
    "    w = model_w(input1)-model_w(input2) #odd\n",
    "    u1 = model_u1(input1)-model_u1(input2) #odd\n",
    "    u2 = model_u2(input1)+model_u2(input2) #even\n",
    "    \n",
    "    \n",
    "    #compute the derivatives (only first orders)\n",
    "    w_1 = grad(w.sum(), x1, create_graph=True)[0]\n",
    "    w_2 = grad(w.sum(), x2, create_graph=True)[0]\n",
    "    phi_1 = grad(phi.sum(), x1, create_graph=True)[0]\n",
    "    phi_2 = grad(phi.sum(), x2, create_graph=True)[0]\n",
    "    psi_1 = grad(psi.sum(), x1, create_graph=True)[0]\n",
    "    psi_2 = grad(psi.sum(), x2, create_graph=True)[0]\n",
    "    u1_1 = grad(u1.sum(), x1, create_graph=True)[0]\n",
    "    u1_2 = grad(u1.sum(), x2, create_graph=True)[0]\n",
    "    u2_1 = grad(u1.sum(), x1, create_graph=True)[0]\n",
    "    u2_2 = grad(u1.sum(), x2, create_graph=True)[0]\n",
    "    \n",
    "    #compute the equation residue\n",
    "    N_e = 6\n",
    "    f_1 = w+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*w_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*w_2-phi\n",
    "    f_2 = (2+u1_1/torch.cosh(x1))*phi+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*phi_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*phi_2+u2_1/torch.cosh(x1)*psi\n",
    "    f_3 = (2+u2_2/torch.cosh(x2))*psi+((1+l)*torch.sinh(x1)+u1)/torch.cosh(x1)*psi_1+((1+l)*torch.sinh(x2)+u2)/torch.cosh(x2)*psi_2+u1_2/torch.cosh(x2)*phi\n",
    "    f_4 = u1_1/torch.cosh(x1)+u2_2/torch.cosh(x2)\n",
    "    f_5 = w-(u1_2/torch.cosh(x2)-u2_1/torch.cosh(x1))\n",
    "    f_6 = phi_2/torch.cosh(x2)-psi_1/torch.cosh(x1)\n",
    "    \n",
    "    loss_i_1=torch.norm(f_1)**2/batchsize\n",
    "    loss_i_2=torch.norm(f_2)**2/batchsize\n",
    "    loss_i_3=torch.norm(f_3)**2/batchsize\n",
    "    loss_i_4=torch.norm(f_4)**2/batchsize\n",
    "    loss_i_5=torch.norm(f_5)**2/batchsize\n",
    "    loss_i_6=torch.norm(f_6)**2/batchsize\n",
    "    \n",
    "    loss_i = (loss_i_1+loss_i_2+loss_i_3+loss_i_4+loss_i_5+loss_i_6)/N_e\n",
    "    \n",
    "    ###boundary loss\n",
    "    # sample points\n",
    "    y1 = 2*c*(torch.rand(batchsize1, 1, device=device)-1/2)# (batch1, 1)\n",
    "    y1.requires_grad=True\n",
    "    y2 = c*torch.rand(batchsize1, 1, device=device) # (batch1, 1)\n",
    "    y2.requires_grad=True\n",
    "    y0 = torch.zeros(batchsize1,1, device=device,requires_grad=True)\n",
    "    yd = c*torch.ones(batchsize1,1, device=device)\n",
    "    yd.requires_grad=True\n",
    "    \n",
    "    #boundary 1\n",
    "    input1_b1 = torch.cat([y1,y0], dim=-1) # (batch1, 2)\n",
    "    input2_b1 = torch.cat([-y1,y0], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u2_b1 = model_u2(input1_b1)+model_u2(input2_b1) #even\n",
    "    b_1 = u2_b1\n",
    "    loss_b_1 = torch.norm(b_1)**2/batchsize1\n",
    "    \n",
    "    #boundary 2\n",
    "    o1 = torch.zeros(1,1, device=device,requires_grad=True)\n",
    "    o2 = torch.zeros(1,1, device=device,requires_grad=True)\n",
    "    input_b2 = torch.cat([o1,o2], dim=-1)\n",
    "    \n",
    "    w_b2 = 2*model_w(input_b2)# odd derivative\n",
    "    w_1_b2 = grad(w_b2.sum(), o1, create_graph=True)[0]\n",
    "    b_2 = w_1_b2+1\n",
    "    loss_b_2 = torch.norm(b_2)**2\n",
    "    \n",
    "    #boundary 3,5,7\n",
    "    input1_b3 = torch.cat([yd,y2], dim=-1) # (batch1, 2)\n",
    "    input2_b3 = torch.cat([-yd,y2], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u1_b3 = model_u1(input1_b3)-model_u1(input2_b3) #odd\n",
    "    u2_b3 = model_u2(input1_b3)+model_u2(input2_b3) #even\n",
    "    phi_b3 = model_phi(input1_b3)-model_phi(input2_b3)# odd\n",
    "    psi_b3 = model_psi(input1_b3)+model_psi(input2_b3)# even\n",
    "    u1_1_b3 = grad(u1_b3.sum(), yd, create_graph=True)[0]\n",
    "    u2_2_b3 = grad(u2_b3.sum(), y2, create_graph=True)[0]\n",
    "    b_31=u1_1_b3/torch.cosh(yd)\n",
    "    b_32=u2_2_b3/torch.cosh(y2)\n",
    "    b_5=phi_b3\n",
    "    b_7=psi_b3\n",
    "    loss_b_3 = (torch.norm(b_31)**2+torch.norm(b_32)**2+torch.norm(b_5)**2+torch.norm(b_7)**2)/batchsize1\n",
    "    \n",
    "    #boundary 4,6,8\n",
    "    input1_b4 = torch.cat([y1,yd], dim=-1) # (batch1, 2)\n",
    "    input2_b4 = torch.cat([-y1,yd], dim=-1) # (batch1, 2)\n",
    "    \n",
    "    u1_b4 = model_u1(input1_b4)-model_u1(input2_b4) #odd\n",
    "    u2_b4 = model_u2(input1_b4)+model_u2(input2_b4) #even\n",
    "    phi_b4 = model_phi(input1_b4)-model_phi(input2_b4)# odd\n",
    "    psi_b4 = model_psi(input1_b4)+model_psi(input2_b4)# even\n",
    "    u1_1_b4 = grad(u1_b4.sum(), y1, create_graph=True)[0]\n",
    "    u2_2_b4 = grad(u2_b4.sum(), yd, create_graph=True)[0]\n",
    "    b_41=u1_1_b4/torch.cosh(y1)\n",
    "    b_42=u2_2_b4/torch.cosh(yd)\n",
    "    b_6=phi_b4\n",
    "    b_8=psi_b4\n",
    "    loss_b_4 = (torch.norm(b_41)**2+torch.norm(b_42)**2+torch.norm(b_6)**2+torch.norm(b_8)**2)/batchsize1\n",
    "    \n",
    "    #collect the residue\n",
    "    N_b=8\n",
    "    loss_b = (loss_b_1+loss_b_2+loss_b_3+loss_b_4)/N_b\n",
    "    \n",
    "    ### smoothness loss\n",
    "    # sample points uniformly in the transformed coordinates [-1,1]x[0,1]\n",
    "    z1 = 2*(torch.rand(batchsize, 1, device=device)-1/2)# (batch, 1)\n",
    "    z1.requires_grad=True\n",
    "    z2 = torch.rand(batchsize, 1, device=device) # (batch, 1)\n",
    "    z2.requires_grad=True\n",
    "    input1_s = torch.cat([z1,z2], dim=-1) # (batch, 2)\n",
    "    input2_s = torch.cat([-z1,z2], dim=-1) # (batch, 2)\n",
    "    phi_s = model_phi(input1_s)-model_phi(input2_s) # odd  parity\n",
    "    psi_s = model_psi(input1_s)+model_psi(input2_s) #even\n",
    "    w_s = model_w(input1_s)-model_w(input2_s) #odd\n",
    "    u1_s = model_u1(input1_s)-model_u1(input2_s) #odd\n",
    "    u2_s = model_u2(input1_s)+model_u2(input2_s) #even\n",
    "    \n",
    "    \n",
    "    #compute the derivatives (only first orders)\n",
    "    w_1_s = grad(w_s.sum(), z1, create_graph=True)[0]\n",
    "    w_2_s = grad(w_s.sum(), z2, create_graph=True)[0]\n",
    "    phi_1_s = grad(phi_s.sum(), z1, create_graph=True)[0]\n",
    "    phi_2_s = grad(phi_s.sum(), z2, create_graph=True)[0]\n",
    "    psi_1_s = grad(psi_s.sum(), z1, create_graph=True)[0]\n",
    "    psi_2_s = grad(psi_s.sum(), z2, create_graph=True)[0]\n",
    "    u1_1_s = grad(u1_s.sum(), z1, create_graph=True)[0]\n",
    "    u1_2_s = grad(u1_s.sum(), z2, create_graph=True)[0]\n",
    "    u2_1_s = grad(u1_s.sum(), z1, create_graph=True)[0]\n",
    "    u2_2_s = grad(u1_s.sum(), z2, create_graph=True)[0]\n",
    "    \n",
    "    #compute the equation residue\n",
    "    f_1_s = w_s+((1+l)*torch.sinh(z1)+u1_s)/torch.cosh(z1)*w_1_s+((1+l)*torch.sinh(z2)+u2_s)/torch.cosh(z2)*w_2_s-phi_s\n",
    "    f_2_s = (2+u1_1_s/torch.cosh(z1))*phi_s+((1+l)*torch.sinh(z1)+u1_s)/torch.cosh(z1)*phi_1_s+((1+l)*torch.sinh(z2)+u2_s)/torch.cosh(z2)*phi_2_s+u2_1_s/torch.cosh(z1)*psi_s\n",
    "    f_3_s = (2+u2_2_s/torch.cosh(z2))*psi_s+((1+l)*torch.sinh(z1)+u1_s)/torch.cosh(z1)*psi_1_s+((1+l)*torch.sinh(z2)+u2_s)/torch.cosh(z2)*psi_2_s+u1_2_s/torch.cosh(z2)*phi_s\n",
    "    f_4_s = u1_1_s/torch.cosh(z1)+u2_2_s/torch.cosh(z2)\n",
    "    f_5_s = w_s-(u1_2_s/torch.cosh(z2)-u2_1_s/torch.cosh(z1))\n",
    "    f_6_s = phi_2_s/torch.cosh(z2)-psi_1_s/torch.cosh(z1)\n",
    "    \n",
    "    #compute the residue derivatives\n",
    "    F_1_1=grad(f_1_s.sum(), z1, create_graph=True)[0]\n",
    "    F_1_2=grad(f_1_s.sum(), z2, create_graph=True)[0]\n",
    "    F_2_1=grad(f_2_s.sum(), z1, create_graph=True)[0]\n",
    "    F_2_2=grad(f_2_s.sum(), z2, create_graph=True)[0]\n",
    "    F_3_1=grad(f_3_s.sum(), z1, create_graph=True)[0]\n",
    "    F_3_2=grad(f_3_s.sum(), z2, create_graph=True)[0]\n",
    "    F_4_1=grad(f_4_s.sum(), z1, create_graph=True)[0]\n",
    "    F_4_2=grad(f_4_s.sum(), z2, create_graph=True)[0]\n",
    "    F_5_1=grad(f_5_s.sum(), z1, create_graph=True)[0]\n",
    "    F_5_2=grad(f_5_s.sum(), z2, create_graph=True)[0]\n",
    "    F_6_1=grad(f_6_s.sum(), z1, create_graph=True)[0]\n",
    "    F_6_2=grad(f_6_s.sum(), z2, create_graph=True)[0]\n",
    "    \n",
    "\n",
    "    loss_s_1=(torch.norm(F_1_1)**2+torch.norm(F_1_2)**2)/batchsize1\n",
    "    loss_s_2=(torch.norm(F_2_1)**2+torch.norm(F_2_2)**2)/batchsize1\n",
    "    loss_s_3=(torch.norm(F_3_1)**2+torch.norm(F_3_2)**2)/batchsize1\n",
    "    loss_s_4=(torch.norm(F_4_1)**2+torch.norm(F_4_2)**2)/batchsize1\n",
    "    loss_s_5=(torch.norm(F_5_1)**2+torch.norm(F_5_2)**2)/batchsize1\n",
    "    loss_s_6=(torch.norm(F_6_1)**2+torch.norm(F_6_2)**2)/batchsize1\n",
    "    \n",
    "    loss_s = (loss_s_1+loss_s_2+loss_s_3+loss_s_4+loss_s_5+loss_s_6)/N_e\n",
    "    \n",
    "    \n",
    "    #the total loss\n",
    "    gamma=0.1\n",
    "    loss =gamma*(loss_i+loss_s)+1*loss_b\n",
    "\n",
    "    # update the model\n",
    "    loss.backward()\n",
    "    nn_optimizer.step()\n",
    "    #nn_scheduler.step()\n",
    "\n",
    "    l_optimizer.step()\n",
    "    #l_scheduler.step()\n",
    "\n",
    "    # plot\n",
    "    if ep % 10 == 0:\n",
    "        print(\"Epoch is {},  function loss is {}, boundary loss is {}, smoothness loss is {}, overall loss is {} \".format(ep, loss_i.item(),loss_b.item(),loss_s.item(), loss.item()))\n",
    "        #print(ep, 'loss' +{loss_i.item()}, loss_b.item(),loss1.item(),loss2.item(), loss.item())\n",
    "        print(l)\n",
    "        # uniformly sample from [r,z] \n",
    "        if ep % 100 == 0:\n",
    "            nr=1000\n",
    "            nz=500\n",
    "            gridr = np.linspace(-20, 20,num=nr)\n",
    "            gridz = np.linspace(0, 20, num=nz)\n",
    "            rr, zz = np.meshgrid(gridr,gridz)\n",
    "            input1 = np.stack([rr, zz], axis=2).reshape(nr*nz,2)\n",
    "            input1 = torch.tensor([input1]).to(device)\n",
    "            input2 = np.stack([-rr, zz], axis=2).reshape(nr*nz,2)\n",
    "            input2 = torch.tensor([input2]).to(device)\n",
    "            #print(input.shape)\n",
    "            phi = model_phi(input1).reshape(nz,nr)-model_phi(input2).reshape(nz,nr) # odd  parity\n",
    "            psi = model_psi(input1).reshape(nz,nr)+model_psi(input2).reshape(nz,nr) #even\n",
    "            w = model_w(input1).reshape(nz,nr)-model_w(input2).reshape(nz,nr) #odd\n",
    "            u1 = model_u1(input1).reshape(nz,nr)-model_u1(input2).reshape(nz,nr) #odd\n",
    "            u2 = model_u2(input1).reshape(nz,nr)+model_u2(input2).reshape(nz,nr) #even\n",
    "            plt.imshow(u1.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "            plt.imshow(u2.detach().cpu().numpy())\n",
    "            plt.show()\n",
    "            #phi = model_phi(input1)+model_phi(input2)-model_phi(input3)-model_phi(input4) # odd and even parity\n",
    "            #u = model_u(input1)+model_u(input2)-model_u(input3)-model_u(input4)\n",
    "            #w = model_w(input1)+model_w(input2)-model_w(input3)-model_w(input4)\n",
    "            #plt.plot(input1.detach().cpu().numpy(), phi.detach().cpu().numpy())\n",
    "            #plt.show()\n",
    "            #plt.plot(input1.detach().cpu().numpy(), u.detach().cpu().numpy())\n",
    "            #plt.show()\n",
    "            #plt.plot(input1.detach().cpu().numpy(), w.detach().cpu().numpy())\n",
    "            #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check limiting behavior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
